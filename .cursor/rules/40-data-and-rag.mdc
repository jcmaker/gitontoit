---
description: 데이터, 인덱싱, RAG (Stateless / No-DB)
alwaysApply: true
---

## 인덱싱 파이프라인 (요청 단위)

1. GitHub 트리/파일 수집 → 2) **텍스트 파일만 선별** → 3) **청킹** → 4) **임베딩 생성(인메모리 보관)** → 5) **검색/QA 후 폐기**

- 바이너리/대형 파일(> 200KB), lock/빌드 산출물 제외
- 확장자 allowlist: ts, tsx, js, jsx, md, mdx, py, go, rs, java, kt, rb, php, c, cpp, cs, sql, json
- 긴 파일은 앞/중/뒤 **샘플링**으로 크기 가드

## 청킹

- 목표 크기 **~600 토큰**, **오버랩 ~120** (문자 길이로 근사)
- 함수/문단 경계(빈 줄, `}` 등)에서 우선 분할
- 파일당 최대 라인 수 제한(예: 5,000줄) 및 방어 코드 포함

## 임베딩

- OpenAI 임베딩 **배치 처리**(권장 256~512개 단위)
- 입력이 너무 길면 안전하게 절단
- 실패 시 **지수 백오프**로 최대 2회 재시도, 그래도 실패면 중단/리포트

## 검색

- 쿼리 임베딩 → **코사인 유사도**로 top-k (기본 8)
- 스니펫은 매칭 위치 중심 ±200자
- (선택) 간단 재랭킹 가능하지만 기본은 코사인 우선

## LLM 사용

- 컨텍스트는 **압축/요약** 후 주입(중복 제거, 불필요 토큰 최소화)
- **출처(파일 경로/청크 idx)**를 항상 포함
- 불확실하면 **모른다고 명시**

## 비용/성능 가드

- 전체 파이프라인 **타임아웃**(예: 60–90s)
- 외부 호출 **동시성 제한**(p-limit ~10)
- 동일 리포 반복 요청 빈다면 **repo@sha 캐시** 고려(선택, KV/Edge)

## 저장 정책

- **영구 저장 없음**(Stateless). 요청 처리 후 인메모리 리소스 폐기.
- 캐시 도입 시에도 **사용자 동의/공지** 및 TTL 설정 필수.
